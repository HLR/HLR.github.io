%2025
@inproceedings{
sinha2025a,
title={A Comparative Analysis of NeSy Frameworks and What's Next?},
author={Sania Sinha and Tanawan Premsri and Parisa Kordjamshidi},
booktitle={19th International Conference on Neurosymbolic Learning and Reasoning},
year={2025},
url={https://openreview.net/forum?id=psXDX4Q8E5}
}

@article{Kamali_Barezi_Kordjamshidi_2025,
title={NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional Generalization},
volume={39},
url={https://ojs.aaai.org/index.php/AAAI/article/view/32439},
DOI={10.1609/aaai.v39i4.32439},
number={4},
journal={Proceedings of the AAAI Conference on Artificial Intelligence},
author={Kamali, Danial and Barezi, Elham J. and Kordjamshidi, Parisa},
year={2025},
month={Apr.},
pages={4184-4193}
}

@inproceedings{premsri-kordjamshidi-2025-neuro,
    title = "Neuro-symbolic Training for Reasoning over Spatial Language",
    author = "Premsri, Tanawan  and
      Kordjamshidi, Parisa",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2025",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-naacl.128/",
    pages = "2395--2414",
    ISBN = "979-8-89176-195-7",
    abstract = "Spatial reasoning based on natural language expressions is essential for everyday human tasks. This reasoning ability is also crucial for machines to interact with their environment in a human-like manner. However, recent research shows that even state-of-the-art language models struggle with spatial reasoning over text, especially when facing nesting spatial expressions. This is attributed to not achieving the right level of abstraction required for generalizability.To alleviate this issue, we propose training language models with neuro-symbolic techniques that exploit the spatial logical rules as constraints, providing additional supervision to improve spatial reasoning and question answering.Training language models to adhere to spatial reasoning rules guides them in making more effective and general abstractions for transferring spatial knowledge to various domains. We evaluate our approach on existing spatial question-answering benchmarks. Our results indicate the effectiveness of our proposed technique in improving language models in complex multi-hop spatial reasoning over text."
}

@inproceedings{
anonymous2025do,
title={Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference under Ambiguities},
author={Anonymous},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=84pDoCD4lH}
}

@inproceedings{nafar-etal-2025-learning,
    title = "Learning vs Retrieval: The Role of In-Context Examples in Regression with Large Language Models",
    author = "Nafar, Aliakbar  and
      Venable, K. Brent  and
      Kordjamshidi, Parisa",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-long.417/",
    pages = "8206--8229",
    ISBN = "979-8-89176-189-6",
    abstract = "Generative Large Language Models (LLMs) are capable of being in-context learners. However, the underlying mechanism of in-context learning (ICL) is still a major research question, and experimental research results about how models exploit ICL are not always consistent. In this work, we propose a framework for evaluating in-context learning mechanisms, which we claim are a combination of retrieving internal knowledge and learning from in-context examples by focusing on regression tasks. First, we show that LLMs can solve real-world regression problems and then design experiments to measure the extent to which the LLM retrieves its internal knowledge versus learning from in-context examples. We argue that this process lies on a spectrum between these two extremes. We provide an in-depth analysis of the degrees to which these mechanisms are triggered depending on various factors, such as prior knowledge about the tasks and the type and richness of the information provided by the in-context examples. We employ three LLMs and utilize multiple datasets to corroborate the robustness of our findings. Our results shed light on how to engineer prompts to leverage meta-learning from in-context examples and foster knowledge retrieval depending on the problem being addressed."
}

@article{Nafar_Venable_Kordjamshidi_2025, 
  title={Reasoning over Uncertain Text by Generative Large Language Models}, 
  volume={39}, url={https://ojs.aaai.org/index.php/AAAI/article/view/34674}, 
  DOI={10.1609/aaai.v39i23.34674}, 
  abstractNote={This paper considers the challenges Large Language Models (LLMs) face when reasoning over text that includes information involving uncertainty explicitly quantified via probability values. This type of reasoning is relevant to a variety of contexts ranging from everyday conversations to medical decision-making. Despite improvements in the mathematical reasoning capabilities of LLMs, they still exhibit significant difficulties when it comes to probabilistic reasoning. To deal with this problem, we introduce the Bayesian Linguistic Inference Dataset (BLInD), a new dataset specifically designed to test the probabilistic reasoning capabilities of LLMs. We use BLInD to find out the limitations of LLMs for tasks involving probabilistic reasoning. In addition, we present several prompting strategies that map the problem to different formal representations, including Python code, probabilistic algorithms, and probabilistic logical programming. We conclude by providing an evaluation of our methods on BLInD and an adaptation of a causal reasoning question-answering dataset. Our empirical results highlight the effectiveness of our proposed strategies for multiple LLMs.}, 
  number={23}, 
  journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
  author={Nafar, Aliakbar and Venable, Kristen Brent and Kordjamshidi, Parisa}, 
  year={2025}, 
  month={Apr.}, 
  pages={24911-24920} 
}

@inproceedings{
zhang2025spartund,
title={{SPARTUN}3D: Situated Spatial Understanding of 3D World in Large Language Model},
author={Yue Zhang and Zhiyang Xu and Ying Shen and Parisa Kordjamshidi and Lifu Huang},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=FGMkSL8NR0}
}

%2024

@article{
zhang2024visionandlanguage,
title={Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models},
author={Yue Zhang and Ziqiao Ma and Jialu Li and Yanyuan Qiao and Zun Wang and Joyce Chai and Qi Wu and Mohit Bansal and Parisa Kordjamshidi},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=yiqeh2ZYUh},
note={Survey Certification}
}
@article{
sinha2024a,
title={A Survey on Compositional Learning of {AI} Models: Theoretical and Experimental Practices},
author={Sania Sinha and Tanawan Premsri and Parisa Kordjamshidi},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=BXDxwItNqQ},
note={Survey Certification}
}
@article{KPODO2024109349,
title = {AgXQA: A benchmark for advanced Agricultural Extension question answering},
journal = {Computers and Electronics in Agriculture},
volume = {225},
pages = {109349},
year = {2024},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2024.109349},
url = {https://www.sciencedirect.com/science/article/pii/S0168169924007403},
author = {Josué Kpodo and Parisa Kordjamshidi and A. Pouyan Nejadhashemi},
keywords = {Agricultural Extension, Question-Answering, Annotated Dataset, Large Language Models, Zero-Shot Learning},
}

@inproceedings{
zhang2024narrowing,
title={Narrowing the Gap between Vision and Action in Navigation},
author={Yue Zhang and Parisa Kordjamshidi},
booktitle={ACM Multimedia 2024},
year={2024},
url={https://openreview.net/forum?id=vscynaeAJn}
}

@inproceedings{10.1007/978-3-031-72655-2_23,
author = {Cheng, Zixu and Pu, Yujiang and Gong, Shaogang and Kordjamshidi, Parisa and Kong, Yu},
title = {SHINE: Saliency-Aware Hierarchical Negative Ranking for Compositional Temporal Grounding},
year = {2024},
isbn = {978-3-031-72654-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-72655-2_23},
doi = {10.1007/978-3-031-72655-2_23},
booktitle = {Computer Vision – ECCV 2024: 18th European Conference, Milan, Italy, September 29–October 4, 2024, Proceedings, Part XIX},
pages = {398–416},
numpages = {19},
keywords = {Temporal Grounding, Compositional Generalization},
location = {Milan, Italy}
}


@inproceedings{10.1007/978-3-031-71170-1_25,
author = {Faghihi, Hossein Rajaby and Nafar, Aliakbar and Uszok, Andrzej and Karimian, Hamid and Kordjamshidi, Parisa},
title = {Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language},
year = {2024},
isbn = {978-3-031-71169-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-71170-1_25},
doi = {10.1007/978-3-031-71170-1_25},
pages = {315–327},
numpages = {13},
keywords = {Neuro-Symbolic AI, Code Generation, Constraint Integration, Declarative Programming, Language to Code, Generative AI, Large Language Models},
location = {Barcelona, Spain}
}


@inproceedings{kamali-etal-2024-using-persuasive,
    title = "Using Persuasive Writing Strategies to Explain and Detect Health Misinformation",
    author = "Kamali, Danial  and
      Romain, Joseph D.  and
      Liu, Huiyi  and
      Peng, Wei  and
      Meng, Jingbo  and
      Kordjamshidi, Parisa",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.1501",
    pages = "17285--17309",
    abstract = "Nowadays, the spread of misinformation is a prominent problem in society. Our research focuses on aiding the automatic identification of misinformation by analyzing the persuasive strategies employed in textual documents. We introduce a novel annotation scheme encompassing common persuasive writing tactics to achieve our objective. Additionally, we provide a dataset on health misinformation, thoroughly annotated by experts utilizing our proposed scheme. Our contribution includes proposing a new task of annotating pieces of text with their persuasive writing strategy types. We evaluate fine-tuning and prompt-engineering techniques with pre-trained language models of the BERT family and the generative large language models of the GPT family using persuasive strategies as an additional source of information. We evaluate the effects of employing persuasive strategies as intermediate labels in the context of misinformation detection. Our results show that those strategies enhance accuracy and improve the explainability of misinformation detection models. The persuasive strategies can serve as valuable insights and explanations, enabling other models or even humans to make more informed decisions regarding the trustworthiness of the information.",
}

@inproceedings{rajaby-faghihi-kordjamshidi-2024-consistent,
    title = "Consistent Joint Decision-Making with Heterogeneous Learning Models",
    author = "Rajaby Faghihi, Hossein  and
      Kordjamshidi, Parisa",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.53",
    pages = "803--813",
    abstract = "This paper introduces a novel decision-making framework that promotes consistency among decisions made by diverse models while utilizing external knowledge. Leveraging the Integer Linear Programming(ILP) framework, we map predictions from various models into globally normalized and comparable values by incorporating information about decisions{'} prior probability, confidence (uncertainty), and the models{'} expected accuracy. Our empirical study demonstrates the superiority of our approach over conventional baselines on multiple datasets.",
}

@inproceedings{zhang-etal-2024-navhint,
    title = "{N}av{H}int: Vision and Language Navigation Agent with a Hint Generator",
    author = "Zhang, Yue  and
      Guo, Quan  and
      Kordjamshidi, Parisa",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.7",
    pages = "92--103",
    abstract = "The existing work on vision and language navigation mainly relies on navigation-related losses to establish the connection between vision and language modalities, neglecting aspects of helping the navigation agent build a deep understanding of the visual environment.In our work, we provide indirect supervision to the navigation agent through a hint generator that provides detailed visual descriptions.The hint generator assists the navigation agent in developing a global understanding of the visual environment. It directs the agent{'}s attention toward related navigation details, including the relevant sub-instruction, potential challenges in recognition and ambiguities in grounding, and the targeted viewpoint description. To train the hint generator, we construct a synthetic dataset based on landmarks in the instructions and visible and distinctive objects in the visual environment.We evaluate our method on the R2R and R4R datasets and achieve state-of-the-art on several metrics. The experimental results demonstrate that generating hints not only enhances the navigation performance but also helps improve the agent{'}s interpretability.",
}

@inproceedings{nafar-etal-2024-teaching,
    title = "Teaching Probabilistic Logical Reasoning to Transformers",
    author = "Nafar, Aliakbar  and
      Venable, K. Brent  and
      Kordjamshidi, Parisa",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.112",
    pages = "1615--1632",
    abstract = "In this paper, we evaluate the capability of transformer-based language models in making inferences over uncertain text that includes uncertain rules of reasoning. We cover both Pre-trained Language Models (PLMs) and generative Large Language Models (LLMs). Our evaluation results show that both generations of language models struggle with reasoning over uncertain text. We propose a novel end-to-end fine-tuning approach, Probabilistic Constraint Training (PCT), that utilizes probabilistic logical rules as constraints in the fine-tuning phase without relying on these rules in the inference stage. To assess the effectiveness of PCT, we utilize the related corpora and, additionally, create a new and more challenging benchmark that, unlike the previous ones, uses instance-specific rules. Our study demonstrates that PCT improves the transformer-based language model{'}s intrinsic reasoning and makes their probabilistic logical reasoning process more explicit and explainable. Furthermore, PCT equips these models to effectively handle novel situations, including higher reasoning depth, new domains, and complex probabilistic structures.",
}


@inproceedings{10484069,
  author={Xu, Guangyue and Chai, Joyce and Kordjamshidi, Parisa},
  booktitle={2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={GIPCOL: Graph-Injected Soft Prompting for Compositional Zero-Shot Learning}, 
  year={2024},
  volume={},
  number={},
  pages={5762-5771},
  keywords={Training;Computer vision;Image recognition;Zero-shot learning;Computational modeling;Training data;Benchmark testing;Algorithms;Vision + language and/or other modalities;Algorithms;Machine learning architectures;formulations;and algorithms},
  doi={10.1109/WACV57701.2024.00567}}


%2023
@inproceedings{kamali-kordjamshidi-2023-syntax,
    title = "Syntax-Guided Transformers: Elevating Compositional Generalization and Grounding in Multimodal Environments",
    author = "Kamali, Danial  and
      Kordjamshidi, Parisa",
    editor = "Hupkes, Dieuwke  and
      Dankers, Verna  and
      Batsuren, Khuyagbaatar  and
      Sinha, Koustuv  and
      Kazemnejad, Amirhossein  and
      Christodoulopoulos, Christos  and
      Cotterell, Ryan  and
      Bruni, Elia",
    booktitle = "Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.genbench-1.10",
    doi = "10.18653/v1/2023.genbench-1.10",
    pages = "130--142",
    abstract = "Compositional generalization, the ability of intelligent models to extrapolate understanding of components to novel compositions, is a fundamental yet challenging facet in AI research, especially within multimodal environments. In this work, we address this challenge by exploiting the syntactic structure of language to boost compositional generalization. This paper elevates the importance of syntactic grounding, particularly through attention masking techniques derived from text input parsing. We introduce and evaluate the merits of using syntactic information in the multimodal grounding problem. Our results on grounded compositional generalization underscore the positive impact of dependency parsing across diverse tasks when utilized with Weight Sharing across the Transformer encoder. The results push the state-of-the-art in multimodal grounding and parameter-efficient modeling and provide insights for future research.",
}

@inproceedings{mirzaee-kordjamshidi-2023-disentangling,
    title = "Disentangling Extraction and Reasoning in Multi-hop Spatial Reasoning",
    author = "Mirzaee, Roshanak  and
      Kordjamshidi, Parisa",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.221",
    doi = "10.18653/v1/2023.findings-emnlp.221",
    pages = "3379--3397",
    abstract = "Spatial reasoning over text is challenging as the models not only need to extract the direct spatial information from the text but also reason over those and infer implicit spatial relations. Recent studies highlight the struggles even large language models encounter when it comes to performing spatial reasoning over text. In this paper, we explore the potential benefits of disentangling the processes of information extraction and reasoning in models to address this challenge. To explore this, we design various models that disentangle extraction and reasoning(either symbolic or neural) and compare them with state-of-the-art(SOTA) baselines with no explicit design for these parts. Our experimental results consistently demonstrate the efficacy of disentangling, showcasing its ability to enhance models{'} generalizability within realistic data domains.",
}

@inproceedings{xu-etal-2023-metarevision,
    title = "{M}eta{R}e{V}ision: Meta-Learning with Retrieval for Visually Grounded Compositional Concept Acquisition",
    author = "Xu, Guangyue  and
      Kordjamshidi, Parisa  and
      Chai, Joyce",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.818",
    doi = "10.18653/v1/2023.findings-emnlp.818",
    pages = "12224--12236",
    abstract = "Humans have the ability to learn novel compositional concepts by recalling primitive concepts acquired from past experience and generalizing these primitive concepts to novel compositions. Inspired by the above human{'}s compositional learning procedure, in this paper, we propose MetaReVision, a retrievalenhanced meta-learning model to solve the visually grounded compositional concept learning problem. The proposed MetaReVision consists of a retrieval module and a meta-learning module which are designed to incorporate retrieved primitive concepts as supporting set to meta-train visual-language models for grounded compositional concept recognition. Through meta-learning from episodes constructed by the retriever, MetaReVision learns a generic compositional representation that can be fast updated to recognize novel composi tional concepts. We create CompCOCO and CompFlickr to benchmark the grounded compositional concept learning. Our experimental results show MetaReVision outperforms other competitive baselines and the retrieval module does plays an important role in this compositional learning process.",
}

@inproceedings{zhang-kordjamshidi-2023-vln,
    title = "{VLN}-Trans: Translator for the Vision and Language Navigation Agent",
    author = "Zhang, Yue  and
      Kordjamshidi, Parisa",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.737",
    doi = "10.18653/v1/2023.acl-long.737",
    pages = "13219--13233",
    abstract = "Language understanding is essential for the navigation agent to follow instructions. We observe two kinds of issues in the instructions that can make the navigation task challenging: 1. The mentioned landmarks are not recognizable by the navigation agent due to the different vision abilities of the instructor and the modeled agent. 2. The mentioned landmarks are applicable to multiple targets, thus not distinctive for selecting the target among the candidate viewpoints. To deal with these issues, we design a translator module for the navigation agent to convert the original instructions into easy-to-follow sub-instruction representations at each step. The translator needs to focus on the recognizable and distinctive landmarks based on the agent{'}s visual abilities and the observed visual environment. To achieve this goal, we create a new synthetic sub-instruction dataset and design specific tasks to train the translator and the navigation agent. We evaluate our approach on Room2Room (R2R), Room4room (R4R), and Room2Room Last (R2R-Last) datasets and achieve state-of-the-art results on multiple benchmarks.",
}

@inproceedings{rajaby-faghihi-etal-2023-role,
    title = "The Role of Semantic Parsing in Understanding Procedural Text",
    author = "Rajaby Faghihi, Hossein  and
      Kordjamshidi, Parisa  and
      Teng, Choh Man  and
      Allen, James",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2023",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-eacl.137",
    doi = "10.18653/v1/2023.findings-eacl.137",
    pages = "1837--1849",
    abstract = "In this paper, we investigate whether symbolic semantic representations, extracted from deep semantic parsers, can help reasoning over the states of involved entities in a procedural text. We consider a deep semantic parser (TRIPS) and semantic role labeling as two sources of semantic parsing knowledge. First, we propose PROPOLIS, a symbolic parsing-based procedural reasoning framework. Second, we integrate semantic parsing information into state-of-the-art neural models to conduct procedural reasoning. Our experiments indicate that explicitly incorporating such semantic knowledge improves procedural understanding. This paper presents new metrics for evaluating procedural reasoning tasks that clarify the challenges and identify differences among neural, symbolic, and integrated models.",
}


@article{Rajaby Faghihi_Nafar_Zheng_Mirzaee_Zhang_Uszok_Wan_Premsri_Roth_Kordjamshidi_2023,
    title="GLUECons: A Generic Benchmark for Learning under Constraints",
    volume="37",
    url="https://ojs.aaai.org/index.php/AAAI/article/view/26143",
    DOI="10.1609/aaai.v37i8.26143",
    number="8",
    journal="Proceedings of the AAAI Conference on Artificial Intelligence",
    author="Rajaby Faghihi, Hossein and Nafar, Aliakbar and Zheng, Chen and Mirzaee, Roshanak and Zhang, Yue and Uszok, Andrzej and Wan, Alexander and Premsri, Tanawan and Roth, Dan and Kordjamshidi, Parisa",
    year="2023",
    month=Jun,
    pages="9552-9561"
  }
% 2022

@inproceedings{mirzaee-kordjamshidi-2022-transfer,
    title = "Transfer Learning with Synthetic Corpora for Spatial Role Labeling and Reasoning",
    author = "Mirzaee, Roshanak and Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.413",
    pages = "6148--6165"
}
@inproceedings{zheng-kordjamshidi-2022-dynamic,
    title = "Dynamic Relevance Graph Network for Knowledge-Aware Question Answering",
    author = "Zheng, Chen  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.116",
    pages = "1357--1366",
    abstract = "This work investigates the challenge of learning and reasoning for Commonsense Question Answering given an external source of knowledge in the form of a knowledge graph (KG). We propose a novel graph neural network architecture, called Dynamic Relevance Graph Network (DRGN). DRGN operates on a given KG subgraph based on the question and answers entities and uses the relevance scores between the nodes to establish new edges dynamically for learning node representations in the graph network. This explicit usage of relevance as graph edges has the following advantages, a) the model can exploit the existing relationships, re-scale the node weights, and influence the way the neighborhood nodes{'} representations are aggregated in the KG subgraph, b) It potentially recovers the missing edges in KG that are needed for reasoning. Moreover, as a byproduct, our model improves handling the negative questions due to considering the relevance between the question node and the graph entities. Our proposed approach shows competitive performance on two QA benchmarks, CommonsenseQA and OpenbookQA, compared to the state-of-the-art published results.",
}

@inproceedings{zhang-kordjamshidi-2022-lovis,
    title = "{LOV}i{S}: Learning Orientation and Visual Signals for Vision and Language Navigation",
    author = "Zhang, Yue  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.505",
    pages = "5745--5754",
    abstract = "Understanding spatial and visual information is essential for a navigation agent who follows natural language instructions. The current Transformer-based VLN agents entangle the orientation and vision information, which limits the gain from the learning of each information source. In this paper, we design a neural agent with explicit Orientation and Vision modules. Those modules learn to ground spatial information and landmark mentions in the instructions to the visual environment more effectively. To strengthen the spatial reasoning and visual perception of the agent, we design specific pre-training tasks to feed and better utilize the corresponding modules in our final navigation model. We evaluate our approach on both Room2room (R2R) and Room4room (R4R) datasets and achieve the state of the art results on both benchmarks.",
}

@inproceedings{zhang-kordjamshidi-2022-explicit,
    title = "Explicit Object Relation Alignment for Vision and Language Navigation",
    author = "Zhang, Yue  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-srw.24",
    doi = "10.18653/v1/2022.acl-srw.24",
    pages = "322--331"
}

@ARTICLE{10.3389/frai.2022.755361,
    AUTHOR={Kordjamshidi, Parisa and Roth, Dan and Kersting, Kristian},   
    TITLE={Declarative Learning-Based Programming as an Interface to AI Systems},      
    JOURNAL={Frontiers in Artificial Intelligence},      
    VOLUME={5},      
    YEAR={2022},      
    URL={https://www.frontiersin.org/article/10.3389/frai.2022.755361},       
    DOI={10.3389/frai.2022.755361},      
    ISSN={2624-8212},   
}


% 2021
@misc{faghihi2021domiknows,
    title = "{DomiKnowS:} A Library for Integration of Symbolic Domain Knowledge in Deep Learning",
    author = "Hossein Rajaby Faghihi and Quan Guo and Andrzej Uszok and Aliakbar Nafar and Elaheh Raisi and Parisa Kordjamshidi",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP), Demo Track",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
}

@inproceedings{xu-etal-2021-zero,
    title = "Zero-Shot Compositional Concept Learning",
    author = "Xu, Guangyue  and
      Kordjamshidi, Parisa  and
      Chai, Joyce",
    booktitle = "Proceedings of the 1st Workshop on Meta Learning and Its Applications to Natural Language Processing",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.metanlp-1.3",
    doi = "10.18653/v1/2021.metanlp-1.3",
    pages = "19--27",
    abstract = "In this paper, we study the problem of recognizing compositional attribute-object concepts within the zero-shot learning (ZSL) framework. We propose an episode-based cross-attention (EpiCA) network which combines merits of cross-attention mechanism and episode-based training strategy to recognize novel compositional concepts. Firstly, EpiCA bases on cross-attention to correlate conceptvisual information and utilizes the gated pooling layer to build contextualized representations for both images and concepts. The updated representations are used for a more indepth multi-modal relevance calculation for concept recognition. Secondly, a two-phase episode training strategy, especially the ransductive phase, is adopted to utilize unlabeled test examples to alleviate the low-resource learning problem. Experiments on two widelyused zero-shot compositional learning (ZSCL) benchmarks have demonstrated the effectiveness of the model compared with recent approaches on both conventional and generalized ZSCL settings.",
}

@article{zhang2021towards,
  title={Towards Navigation by Reasoning over Spatial Configurations},
  author={Zhang, Yue and Guo, Quan and Kordjamshidi, Parisa},
  journal={ACL workshop on Spatial Language Understanding},
  year={2021}
}

@article{zheng2021relational,
  title={Relational Gating for" What If" Reasoning},
  author={Zheng, Chen and Kordjamshidi, Parisa},
  journal = {IJCAI},
   Year = {2021}
}


@inproceedings{mirzaee-etal-2021-spartqa,
    title = "{SPARTQA}: A Textual Question Answering Benchmark for Spatial Reasoning",
    author = "Mirzaee, Roshanak  and
      Rajaby Faghihi, Hossein  and
      Ning, Qiang  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.364",
    doi = "10.18653/v1/2021.naacl-main.364",
    pages = "4582--4598",
    abstract = "This paper proposes a question-answering (QA) benchmark for spatial reasoning on natural language text which contains more realistic spatial phenomena not covered by prior work and is challenging for state-of-the-art language models (LM). We propose a distant supervision method to improve on this task. Specifically, we design grammar and reasoning rules to automatically generate a spatial description of visual scenes and corresponding QA pairs. Experiments show that further pretraining LMs on these automatically generated data significantly improves LMs{'} capability on spatial understanding, which in turn helps to better solve two external datasets, bAbI, and boolQ. We hope that this work can foster investigations into more sophisticated models for spatial reasoning over text.",
}

@inproceedings{rajaby-faghihi-kordjamshidi-2021-time,
    title = "Time-Stamped Language Model: Teaching Language Models to Understand The Flow of Events",
    author = "Rajaby Faghihi, Hossein  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.362",
    doi = "10.18653/v1/2021.naacl-main.362",
    pages = "4560--4570",
    abstract = "Tracking entities throughout a procedure described in a text is challenging due to the dynamic nature of the world described in the process. Firstly, we propose to formulate this task as a question answering problem. This enables us to use pre-trained transformer-based language models on other QA benchmarks by adapting those to the procedural text understanding. Secondly, since the transformer-based language models cannot encode the flow of events by themselves, we propose a Time-Stamped Language Model (TSLM) to encode event information in LMs architecture by introducing the timestamp encoding. Our model evaluated on the Propara dataset shows improvements on the published state-of-the-art results with a 3.1{\%} increase in F1 score. Moreover, our model yields better results on the location prediction task on the NPN-Cooking dataset. This result indicates that our approach is effective for procedural text understanding in general.",
}
% 2020

@inproceedings{zheng-kordjamshidi-2020-srlgrn,
    title = "{SRLGRN}: Semantic Role Labeling Graph Reasoning Network",
    author = "Zheng, Chen  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.714",
    doi = "10.18653/v1/2020.emnlp-main.714",
    pages = "8881--8891",
    abstract = "This work deals with the challenge of learning and reasoning over multi-hop question answering (QA). We propose a graph reasoning network based on the semantic structure of the sentences to learn cross paragraph reasoning paths and find the supporting facts and the answer jointly. The proposed graph is a heterogeneous document-level graph that contains nodes of type sentence (question, title, and other sentences), and semantic role labeling sub-graphs per sentence that contain arguments as nodes and predicates as edges. Incorporating the argument types, the argument phrases, and the semantics of the edges originated from SRL predicates into the graph encoder helps in finding and also the explainability of the reasoning paths. Our proposed approach shows competitive performance on the HotpotQA distractor setting benchmark compared to the recent state-of-the-art models.",
}

@inproceedings{guo2020inference,
   Author = {Quan Guo and Hossein Rajaby Faghihi and Yue Zhang and Andrzej Uszok and Parisa Kordjamshidi},
   Title = {Inference-Masked Loss for Deep Structured Output Learning},
   Booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI 2020)},
   Year = {2020}
}

@inproceedings{zheng-etal-2020-cross,
    title = "Cross-Modality Relevance for Reasoning on Language and Vision",
    author = "Zheng, Chen  and
      Guo, Quan  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.683",
    doi = "10.18653/v1/2020.acl-main.683",
    pages = "7642--7651",
    abstract = "This work deals with the challenge of learning and reasoning over language and vision data for the related downstream tasks such as visual question answering (VQA) and natural language for visual reasoning (NLVR). We design a novel cross-modality relevance module that is used in an end-to-end framework to learn the relevance representation between components of various input modalities under the supervision of a target task, which is more generalizable to unobserved data compared to merely reshaping the original representation space. In addition to modeling the relevance between the textual entities and visual entities, we model the higher-order relevance between entity relations in the text and object relations in the image. Our proposed approach shows competitive performance on two different language and vision tasks using public benchmarks and improves the state-of-the-art published results. The learned alignments of input spaces and their relevance representations by NLVR task boost the training efficiency of VQA task.",
}

@inproceedings{dan-etal-2020-spatial,
    title = "From Spatial Relations to Spatial Configurations",
    author = "Dan, Soham  and
      Kordjamshidi, Parisa  and
      Bonn, Julia  and
      Bhatia, Archna  and
      Cai, Zheng  and
      Palmer, Martha  and
      Roth, Dan",
    booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://www.aclweb.org/anthology/2020.lrec-1.717",
    pages = "5855--5864",
    abstract = "Spatial Reasoning from language is essential for natural language understanding. Supporting it requires a representation scheme that can capture spatial phenomena encountered in language as well as in images and videos.Existing spatial representations are not sufficient for describing spatial configurations used in complex tasks. This paper extends the capabilities of existing spatial representation languages and increases coverage of the semantic aspects that are needed to ground spatial meaning of natural language text in the world. Our spatial relation language is able to represent a large, comprehensive set of spatial concepts crucial for reasoning and is designed to support composition of static and dynamic spatial configurations. We integrate this language with the Abstract Meaning Representation (AMR) annotation schema and present a corpus annotated by this extended AMR. To exhibit the applicability of our representation scheme, we annotate text taken from diverse datasets and show how we extend the capabilities of existing spatial representation languages with fine-grained decomposition of semantics and blend it seamlessly with AMRs of sentences and discourse representations as a whole.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{rajaby-faghihi-etal-2020-latent,
    title = "Latent Alignment of Procedural Concepts in Multimodal Recipes",
    author = "Rajaby Faghihi, Hossein  and
      Mirzaee, Roshanak  and
      Paliwal, Sudarshan  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the First Workshop on Advances in Language and Vision Research",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.alvr-1.5",
    doi = "10.18653/v1/2020.alvr-1.5",
    pages = "26--31",
    abstract = "We propose a novel alignment mechanism to deal with procedural reasoning on a newly released multimodal QA dataset, named RecipeQA. Our model is solving the textual cloze task which is a reading comprehension on a recipe containing images and instructions. We exploit the power of attention networks, cross-modal representations, and a latent alignment space between instructions and candidate answers to solve the problem. We introduce constrained max-pooling which refines the max pooling operation on the alignment matrix to impose disjoint constraints among the outputs of the model. Our evaluation result indicates a 19{\%} improvement over the baselines.",
}

@article{Ahmadnia_Dorr_Kordjamshidi_2020,
    title={Knowledge Graphs Effectiveness in Neural Machine Translation Improvement},
    volume={21},
    url={https://journals.agh.edu.pl/csci/article/view/3701},
    DOI={10.7494/csci.2020.21.3.3701},
    abstractNote={Neural Machine Translation (NMT) systems require a massive amount of Maintaining semantic relations between words during the translation process yields more accurate target-language output from Neural Machine Translation (NMT). Although difficult to achieve from training data alone, it is possible to leverage Knowledge Graphs (KGs) to retain source-language semantic relations in the corresponding target-language translation. The core idea is to use KG entity relations as embedding constraints to improve the mapping from source to target. This paper describes two embedding constraints, both of which employ Entity Linking (EL)---assigning a unique identity to entities---to associate words in training sentences with those in the KG: (1) a monolingual embedding constraint that supports an enhanced semantic representation of the source words through access to relations between entities in a KG; and (2) a bilingual embedding constraint that forces entity relations in the source-language to be carried over to the corresponding entities in the target-language translation. The method is evaluated for English-Spanish translation exploiting Freebase as a source of knowledge. Our experimental results show that exploiting KG information not only decreases the number of unknown words in the translation but also improves translation quality.},
    number={3},
    journal={Computer Science},
    author={Ahmadnia, Benyamin and Dorr, Bonnie J. and Kordjamshidi, Parisa},
    year={2020},
    month={Sep.}
}

@proceedings{splu-2020-international,
    title = "Proceedings of the Third International Workshop on Spatial Language Understanding",
    editor = "Kordjamshidi, Parisa  and
      Bhatia, Archna  and
      Alikhani, Malihe  and
      Baldridge, Jason  and
      Bansal, Mohit  and
      Moens, Marie-Francine",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.splu-1.0",
}

@inproceedings{kordjamshidi-etal-2020-representation,
    title = "Representation, Learning and Reasoning on Spatial Language for Downstream {NLP} Tasks",
    author = "Kordjamshidi, Parisa  and
      Pustejovsky, James  and
      Moens, Marie-Francine",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-tutorials.5",
    doi = "10.18653/v1/2020.emnlp-tutorials.5",
    pages = "28--33"
}

% 2019

@article{Kordjamshidi2019DeclarativeLP,
  title={Declarative Learning-Based Programming as an Interface to AI Systems},
  author={Parisa Kordjamshidi and D. Roth and K. Kersting},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.07809}
}

@INPROCEEDINGS{8856378,
    author={Karimian, Hamid R. and Pollard, Kevin J. and Moore, Michael J. and Kordjamshidi, Parisa},
    booktitle={2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
    title={Semantic Segmentation of Microengineered Neural Tissues*},
    year={2019},
    volume={},
    number={},
    pages={955-960},
    doi={10.1109/EMBC.2019.8856378}
}


@Article{s19071486,
    AUTHOR = {Gebrehiwot, Asmamaw and Hashemi-Beni, Leila and Thompson, Gary and Kordjamshidi, Parisa and Langan, Thomas E.},
    TITLE = {Deep Convolutional Neural Network for Flood Extent Mapping Using Unmanned Aerial Vehicles Data},
    JOURNAL = {Sensors},
    VOLUME = {19},
    YEAR = {2019},
    NUMBER = {7},
    ARTICLE-NUMBER = {1486},
    URL = {https://www.mdpi.com/1424-8220/19/7/1486},
    ISSN = {1424-8220},
    ABSTRACT = {Flooding is one of the leading threats of natural disasters to human life and property, especially in densely populated urban areas. Rapid and precise extraction of the flooded areas is key to supporting emergency-response planning and providing damage assessment in both spatial and temporal measurements. Unmanned Aerial Vehicles (UAV) technology has recently been recognized as an efficient photogrammetry data acquisition platform to quickly deliver high-resolution imagery because of its cost-effectiveness, ability to fly at lower altitudes, and ability to enter a hazardous area. Different image classification methods including SVM (Support Vector Machine) have been used for flood extent mapping. In recent years, there has been a significant improvement in remote sensing image classification using Convolutional Neural Networks (CNNs). CNNs have demonstrated excellent performance on various tasks including image classification, feature extraction, and segmentation. CNNs can learn features automatically from large datasets through the organization of multi-layers of neurons and have the ability to implement nonlinear decision functions. This study investigates the potential of CNN approaches to extract flooded areas from UAV imagery. A VGG-based fully convolutional network (FCN-16s) was used in this research. The model was fine-tuned and a k-fold cross-validation was applied to estimate the performance of the model on the new UAV imagery dataset. This approach allowed FCN-16s to be trained on the datasets that contained only one hundred training samples, and resulted in a highly accurate classification. Confusion matrix was calculated to estimate the accuracy of the proposed method. The image segmentation results obtained from FCN-16s were compared from the results obtained from FCN-8s, FCN-32s and SVMs. Experimental results showed that the FCNs could extract flooded areas precisely from UAV images compared to the traditional classifiers such as SVMs. The classification accuracy achieved by FCN-16s, FCN-8s, FCN-32s, and SVM for the water class was 97.52%, 97.8%, 94.20% and 89%, respectively.},
    DOI = {10.3390/s19071486}
}

% 2018

@inproceedings{ijcai2018-771,
  title     = {Systems AI: A Declarative Learning Based Programming Perspective},
  author    = {Parisa Kordjamshidi and Dan Roth and Kristian Kersting},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {5464--5471},
  year      = {2018},
  month     = {7},
  doi       = {10.24963/ijcai.2018/771},
  url       = {https://doi.org/10.24963/ijcai.2018/771},
}

@inproceedings{7c79ec9fac8d463fb7ed0ff79189a534,
    title = "Neural Machine Translation advised by Statistical Machine Translation: the case of Farsi-Spanish bilingually low-resource scenario",
    abstract = "In this paper, we propose a sequence-to-sequence NMT model on Farsi-Spanish bilingually low-resource language pair. We apply effective preprocessing steps specific for Farsi language and optimize the model for both translation and transliteration. We also propose a loss function that enhances the word alignment and consequently improves translation quality.",
    keywords = "Natural language processing, Neural machine translation, Statistical machine translation",
    author = "Benyamin Ahmadnia and Parisa Kordjamshidi and Gholamreza Haffari",
    year = "2018",
    doi = "10.1109/ICMLA.2018.00196",
    language = "English",
    isbn = "9781538668061",
    pages = "1209--1213",
    editor = "Wani, {M. Arif} and Mehmed Kantardzic and Moamar Sayed-Mouchaweh and Joao Gama and Edwin Lughofer",
    booktitle = "Proceedings - 17th IEEE International Conference on Machine Learning and Applications",
    publisher = "IEEE, Institute of Electrical and Electronics Engineers",
    address = "United States of America",
    note = "IEEE International Conference on Machine Learning and Applications 2018, ICMLA 2018 ; Conference date: 17-12-2018 Through 20-12-2018",
    url = "https://www.icmla-conference.org/icmla18/",
}


@inproceedings{manzoor-kordjamshidi-2018-anaphora,
    title = "Anaphora Resolution for Improving Spatial Relation Extraction from Text",
    author = "Manzoor, Umar  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the First International Workshop on Spatial Language Understanding",
    month = jun,
    year = "2018",
    address = "New Orleans",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-1407",
    doi = "10.18653/v1/W18-1407",
    pages = "53--62",
    abstract = "Spatial relation extraction from generic text is a challenging problem due to the ambiguity of the prepositions spatial meaning as well as the nesting structure of the spatial descriptions. In this work, we highlight the difficulties that the anaphora can make in the extraction of spatial relations. We use external multi-modal (here visual) resources to find the most probable candidates for resolving the anaphoras that refer to the landmarks of the spatial relations. We then use global inference to decide jointly on resolving the anaphora and extraction of the spatial relations. Our preliminary results show that resolving anaphora improves the state-of-the-art results on spatial relation extraction.",
}

@inproceedings{rahgooy-etal-2018-visually,
    title = "Visually Guided Spatial Relation Extraction from Text",
    author = "Rahgooy, Taher  and
      Manzoor, Umar  and
      Kordjamshidi, Parisa",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-2124",
    doi = "10.18653/v1/N18-2124",
    pages = "788--794",
    abstract = "Extraction of spatial relations from sentences with complex/nesting relationships is very challenging as often needs resolving inherent semantic ambiguities. We seek help from visual modality to fill the information gap in the text modality and resolve spatial semantic ambiguities. We use various recent vision and language datasets and techniques to train inter-modality alignment models, visual relationship classifiers and propose a novel global inference model to integrate these components into our structured output prediction model for spatial role and relation extraction. Our global inference model enables us to utilize the visual and geometric relationships between objects and improves the state-of-art results of spatial information extraction from text.",
}

% 2017

@misc{kordjamshidi2017relational,
      title={Relational Learning and Feature Extraction by Querying over Heterogeneous Information Networks}, 
      author={Parisa Kordjamshidi and Sameer Singh and Daniel Khashabi and Christos Christodoulopoulos and Mark Summons and Saurabh Sinha and Dan Roth},
      year={2017},
      eprint={1707.07794},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{kordjamshidi-etal-2017-spatial,
    title = "Spatial Language Understanding with Multimodal Graphs using Declarative Learning based Programming",
    author = "Kordjamshidi, Parisa  and
      Rahgooy, Taher  and
      Manzoor, Umar",
    booktitle = "Proceedings of the 2nd Workshop on Structured Prediction for Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-4306",
    doi = "10.18653/v1/W17-4306",
    pages = "33--43",
    abstract = "This work is on a previously formalized semantic evaluation task of spatial role labeling (SpRL) that aims at extraction of formal spatial meaning from text. Here, we report the results of initial efforts towards exploiting visual information in the form of images to help spatial language understanding. We discuss the way of designing new models in the framework of declarative learning-based programming (DeLBP). The DeLBP framework facilitates combining modalities and representing various data in a unified graph. The learning and inference models exploit the structure of the unified graph as well as the global first order domain constraints beyond the data to predict the semantics which forms a structured meaning representation of the spatial context. Continuous representations are used to relate the various elements of the graph originating from different modalities. We improved over the state-of-the-art results on SpRL.",
}

@inproceedings{Kordjamshidi2017CLEF2M,
  title={CLEF 2017: Multimodal Spatial Role Labeling Task Working Notes},
  author={Parisa Kordjamshidi and Taher Rahgooy and Marie-Francine Moens and J. Pustejovsky and Umar Manzoor and Kirk Roberts},
  booktitle={CLEF},
  year={2017}
}

@Inbook{Kordjamshidi2017,
    author="Kordjamshidi, Parisa
    and van Otterlo, Martijn
    and Moens, Marie-Francine",
    editor="Ide, Nancy
    and Pustejovsky, James",
    title="Spatial Role Labeling Annotation Scheme",
    bookTitle="Handbook of Linguistic Annotation",
    year="2017",
    publisher="Springer Netherlands",
    address="Dordrecht",
    pages="1025--1052",
    abstract="Spatial information extraction from natural language is important for many applications including geographical information systems, human computer interaction, providing navigational instructions to robots and visualization or text-to-scene conversion. The main obstacles for corpus-based approaches to perform such extractions have been: (a) the lack of an agreement on a unique semantic model for spatial information; (b) the diversity of formal spatial representation models; (c) the gap between the expressiveness of natural language and formal spatial representation models; and consequently, (d) the lack of annotated data on which machine learning can be employed to learn and extract the spatial relations. These items drive the direction of the contributions on which this chapter is built. In this chapter we introduce a spatial annotation scheme built upon the previous research that supports various aspects of spatial semantics, including static and dynamic spatial relations. The annotation scheme is based on the ideas of holistic spatial semantics as well as qualitative spatial reasoning models. Spatial roles, their relations and indicators along with their multiple formal meaning are tagged using the annotation scheme producing a rich spatial language corpus. The goal of building such a corpus is to produce a resource for training the machine learning methods for mapping the language to formal spatial representation models, and to use it as ground-truth data for evaluation.",
    isbn="978-94-024-0881-2",
    doi="10.1007/978-94-024-0881-2_38",
    url="https://doi.org/10.1007/978-94-024-0881-2_38"
}

% 2016

@inproceedings{kordjamshidi-etal-2016-better,
    title = "Better call {S}aul: Flexible Programming for Learning and Inference in {NLP}",
    author = "Kordjamshidi, Parisa  and
      Khashabi, Daniel  and
      Christodoulopoulos, Christos  and
      Mangipudi, Bhargav  and
      Singh, Sameer  and
      Roth, Dan",
    booktitle = "Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",
    month = dec,
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://www.aclweb.org/anthology/C16-1285",
    pages = "3030--3040",
    abstract = "We present a novel way for designing complex joint inference and learning models using Saul (Kordjamshidi et al., 2015), a recently-introduced declarative learning-based programming language (DeLBP). We enrich Saul with components that are necessary for a broad range of learning based Natural Language Processing tasks at various levels of granularity. We illustrate these advances using three different, well-known NLP problems, and show how these generic learning and inference modules can directly exploit Saul{'}s graph-based data representation. These properties allow the programmer to easily switch between different model formulations and configurations, and consider various kinds of dependencies and correlations among variables of interest with minimal programming effort. We argue that Saul provides an extremely useful paradigm both for the design of advanced NLP systems and for supporting advanced research in NLP.",
}

@inproceedings{sammons-etal-2016-edison,
    title = "{EDISON}: Feature Extraction for {NLP}, Simplified",
    author = "Sammons, Mark  and
      Christodoulopoulos, Christos  and
      Kordjamshidi, Parisa  and
      Khashabi, Daniel  and
      Srikumar, Vivek  and
      Roth, Dan",
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://www.aclweb.org/anthology/L16-1645",
    pages = "4085--4092",
    abstract = "When designing Natural Language Processing (NLP) applications that use Machine Learning (ML) techniques, feature extraction becomes a significant part of the development effort, whether developing a new application or attempting to reproduce results reported for existing NLP tasks. We present EDISON, a Java library of feature generation functions used in a suite of state-of-the-art NLP tools, based on a set of generic NLP data structures. These feature extractors populate simple data structures encoding the extracted features, which the package can also serialize to an intuitive JSON file format that can be easily mapped to formats used by ML packages. EDISON can also be used programmatically with JVM-based (Java/Scala) NLP software to provide the feature extractor input. The collection of feature extractors is organised hierarchically and a simple search interface is provided. In this paper we include examples that demonstrate the versatility and ease-of-use of the EDISON feature extraction suite to show that this can significantly reduce the time spent by developers on feature extraction design for NLP systems. The library is publicly hosted at https://github.com/IllinoisCogComp/illinois-cogcomp-nlp/, and we hope that other NLP researchers will contribute to the set of feature extractors. In this way, the community can help simplify reproduction of published results and the integration of ideas from diverse sources when developing new and improved NLP applications.",
}
